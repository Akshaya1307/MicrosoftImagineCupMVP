# ==================================================
# ENHANCED MODEL TRAINING WITH BETTER PERFORMANCE
# ==================================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)

# ==================================================
# 1. IMPROVED DATA GENERATION WITH REALISTIC PATTERNS
# ==================================================

def generate_synthetic_data(n_samples=1500):
    """Generate more realistic student data with correlations"""
    
    data = {
        "student_id": np.arange(1, n_samples + 1),
        
        # Attendance: Bimodal distribution (good vs poor attendees)
        "attendance_pct": np.concatenate([
            np.random.normal(85, 5, n_samples//3),
            np.random.normal(70, 8, n_samples//3),
            np.random.normal(50, 10, n_samples//3)
        ]),
        
        # Scores with correlations
        "assignment_score": np.random.beta(2, 2, n_samples) * 60 + 40,
        "quiz_score": np.random.beta(2.5, 2, n_samples) * 60 + 40,
        "midterm_score": np.random.beta(3, 2, n_samples) * 65 + 35,
        
        # Study hours: correlated with scores
        "study_hours_per_week": np.random.gamma(3, 2, n_samples),
        
        # Previous GPA: strong predictor
        "previous_gpa": np.random.normal(6.5, 1.5, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    # Clip values to realistic ranges
    df["attendance_pct"] = df["attendance_pct"].clip(40, 100)
    df[["assignment_score", "quiz_score", "midterm_score"]] = \
        df[["assignment_score", "quiz_score", "midterm_score"]].clip(35, 100)
    df["study_hours_per_week"] = df["study_hours_per_week"].clip(2, 35)
    df["previous_gpa"] = df["previous_gpa"].clip(3.0, 9.5)
    
    # Create engineered features
    df["overall_score"] = (
        df["assignment_score"] * 0.3 +
        df["quiz_score"] * 0.2 +
        df["midterm_score"] * 0.5
    )
    
    df["attendance_score"] = np.where(
        df["attendance_pct"] > 85, "Excellent",
        np.where(df["attendance_pct"] > 70, "Good", "Poor")
    )
    
    return df

# Generate data
print("ðŸ“Š Generating enhanced synthetic data...")
df = generate_synthetic_data(1500)

# ==================================================
# 2. IMPROVED RISK ASSESSMENT FUNCTION
# ==================================================

def assign_risk_level(row):
    """Multi-factorial risk assessment"""
    
    # Academic performance score (0-100)
    academic_score = (
        row["assignment_score"] * 0.25 +
        row["quiz_score"] * 0.20 +
        row["midterm_score"] * 0.35 +
        row["previous_gpa"] * 10 * 0.20
    )
    
    # Attendance penalty
    if row["attendance_pct"] < 60:
        attendance_multiplier = 0.7
    elif row["attendance_pct"] < 75:
        attendance_multiplier = 0.85
    else:
        attendance_multiplier = 1.0
    
    # Study hours adjustment
    if row["study_hours_per_week"] < 8:
        study_multiplier = 0.8
    elif row["study_hours_per_week"] > 20:
        study_multiplier = 1.1
    else:
        study_multiplier = 1.0
    
    final_score = academic_score * attendance_multiplier * study_multiplier
    
    # Assign risk levels (more nuanced)
    if final_score < 55:
        return "High"
    elif final_score < 68:
        return "Medium"
    else:
        return "Low"

df["academic_risk"] = df.apply(assign_risk_level, axis=1)

# ==================================================
# 3. ADVANCED FEATURE ENGINEERING
# ==================================================

# Remove student_id (not a predictive feature)
df = df.drop("student_id", axis=1)

# Encode categorical variables
le = LabelEncoder()
df["academic_risk_encoded"] = le.fit_transform(df["academic_risk"])
df["attendance_score_encoded"] = LabelEncoder().fit_transform(df["attendance_score"])

# Create interaction features
df["attendance_study_interaction"] = df["attendance_pct"] * df["study_hours_per_week"] / 100
df["gpa_score_ratio"] = df["previous_gpa"] / (df["overall_score"] / 100)

# Check class distribution
print("\nðŸŽ¯ Class Distribution:")
print(df["academic_risk"].value_counts(normalize=True))

# ==================================================
# 4. HANDLE CLASS IMBALANCE WITH SMOTE
# ==================================================

# Prepare features and target
features = df.drop(["academic_risk", "academic_risk_encoded", "attendance_score"], axis=1)
target = df["academic_risk_encoded"]

# Apply SMOTE for oversampling minority classes
print("\nâš–ï¸ Applying SMOTE for class balancing...")
smote = SMOTE(random_state=42, sampling_strategy='auto')
X_resampled, y_resampled = smote.fit_resample(features, target)

# ==================================================
# 5. HYPERPARAMETER TUNING WITH GRID SEARCH
# ==================================================

X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, 
    test_size=0.2, 
    random_state=42,
    stratify=y_resampled
)

# Scale numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define parameter grid
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'class_weight': ['balanced', 'balanced_subsample']
}

print("\nðŸ” Performing Grid Search for optimal parameters...")
rf = RandomForestClassifier(random_state=42)

# Use smaller grid for faster training (adjust for final model)
grid_search = GridSearchCV(
    rf, param_grid, 
    cv=3, 
    scoring='f1_macro',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_scaled, y_train)

print(f"\nâœ… Best Parameters: {grid_search.best_params_}")
print(f"ðŸŽ¯ Best CV Score: {grid_search.best_score_:.3f}")

# ==================================================
# 6. EVALUATE MODEL WITH COMPREHENSIVE METRICS
# ==================================================

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_scaled)
y_proba = best_model.predict_proba(X_test_scaled)

print("\nðŸ“Š MODEL EVALUATION")
print("=" * 50)

# Accuracy
from sklearn.metrics import accuracy_score
print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")

# Classification Report
print("\nðŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Confusion Matrix
print("ðŸ“ˆ Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# ROC-AUC
roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')
print(f"\nðŸ“Š ROC-AUC Score: {roc_auc:.3f}")

# ==================================================
# 7. MODEL INTERPRETABILITY WITH SHAP
# ==================================================

print("\nðŸ” Generating SHAP Explanations...")

# Create SHAP explainer
explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test_scaled)

# Summary plot
shap.summary_plot(shap_values, X_test_scaled, 
                  feature_names=features.columns,
                  class_names=le.classes_,
                  show=False)
plt.title('SHAP Feature Importance')
plt.tight_layout()
plt.savefig('shap_summary.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature importance dataframe
feature_importance = pd.DataFrame({
    'feature': features.columns,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nðŸŽ¯ Top 10 Most Important Features:")
print(feature_importance.head(10))

# ==================================================
# 8. SAVE ENHANCED MODEL PIPELINE
# ==================================================

# Save the full pipeline
pipeline = {
    'model': best_model,
    'scaler': scaler,
    'label_encoder': le,
    'feature_names': list(features.columns),
    'risk_thresholds': {'High': 55, 'Medium': 68, 'Low': 100}
}

joblib.dump(pipeline, 'models/enhanced_student_model.pkl')
print("\nðŸ’¾ Enhanced model pipeline saved successfully!")

# ==================================================
# 9. CALIBRATION AND CONFIDENCE ESTIMATION
# ==================================================

from sklearn.calibration import CalibratedClassifierCV

# Calibrate probabilities for better confidence scores
calibrated_model = CalibratedClassifierCV(best_model, cv=3, method='sigmoid')
calibrated_model.fit(X_train_scaled, y_train)

calibrated_pipeline = {
    'model': calibrated_model,
    'scaler': scaler,
    'label_encoder': le,
    'feature_names': list(features.columns)
}

joblib.dump(calibrated_pipeline, 'models/calibrated_student_model.pkl')
print("âœ… Calibrated model saved for better probability estimates!")